{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import bs4\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task1\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=urls,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task2\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task3\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(\n",
    "    model = \"text-embedding-3-small\"\n",
    "))\n",
    "retriever = vectorstore.as_retriever(\n",
    "    type = \"similarity\",\n",
    "    kwargs={'k':6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task4\n",
    "\n",
    "user_query = 'agent memory'\n",
    "retrieved_chunk = retriever.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevance': 'yes'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#task5\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def evaluate_relevance(query, retrieved_chunk):\n",
    "    parser = JsonOutputParser()\n",
    "\n",
    "    evaluating_prompt = \"\"\"\n",
    "    You are a system designed to evaluate the relevance of retrieved information with respect to a user query.\n",
    "    Based on the provided user query and the retrieved chunk, determine if the retrieved chunk is relevant to the query.\n",
    "    Respond in the JSON format: {{\"relevance\": \"yes\"}} or {{\"relevance\": \"no\"}}.\n",
    "\n",
    "    Input:\n",
    "        • User Query: {user_query}\n",
    "        • Retrieved Chunk: {retrieved_chunk}\n",
    "\n",
    "    Output:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=evaluating_prompt,\n",
    "        input_variables=[\"user_query\", \"retrieved_chunk\"]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    return chain.invoke({\"user_query\": query, \"retrieved_chunk\": retrieved_chunk})\n",
    "\n",
    "\n",
    "evaluate_relevance(user_query, retriever.invoke(user_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 'yes'}\n",
      "{'relevance': 'no'}\n"
     ]
    }
   ],
   "source": [
    "#task6 task7\n",
    "\n",
    "yes_query = \"what is few-shot?\"\n",
    "print(evaluate_relevance(yes_query, retriever.invoke(yes_query)))\n",
    "\n",
    "no_query = \"my name is jacob\"\n",
    "print(evaluate_relevance(no_query, retriever.invoke(no_query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided context does not define \"few-shot.\" Therefore, I don\\'t know the answer.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#task8\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "task4_query = 'agent memory'\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def chat(query, retrieved_chunk):\n",
    "    chunk_to_use = retrieved_chunk\n",
    "    if evaluate_relevance(query, retrieved_chunk)['relevance'] == 'yes':\n",
    "        chunk_to_use = retriever.invoke(task4_query)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda docs: format_docs(chunk_to_use),\n",
    "            \"question\": RunnablePassthrough()       \n",
    "        })\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain.invoke({\"context\": chunk_to_use, \"question\": query})\n",
    "\n",
    "\n",
    "question = \"what is few-shot?\"\n",
    "chat(question, retriever.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hallucination': 'no'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#task9\n",
    "\n",
    "def evaluate_hallucination(generated_answer):\n",
    "    parser = JsonOutputParser()\n",
    "\n",
    "    evaluate_hallucination_prompt = \"\"\"\n",
    "        You are an AI evaluator tasked with identifying hallucinations in generated answers. \n",
    "        A hallucination occurs when the generated answer includes information \n",
    "        that is factually incorrect, fabricated, or unsupported by the given context.\n",
    "\n",
    "        Your task:\n",
    "        1. Analyze the generated answer based on the provided context.\n",
    "        2. Determine if the generated answer includes hallucinated content.\n",
    "\n",
    "        Respond in JSON format:\n",
    "        - If hallucination is detected: {{\"hallucination\": \"yes\"}}\n",
    "        - If no hallucination is detected: {{\"hallucination\": \"no\"}}\n",
    "\n",
    "        Input:\n",
    "        - Generated Answer: {generated_answer}\n",
    "\n",
    "    Output:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=evaluate_hallucination_prompt,\n",
    "        input_variables=[\"generated_answer\"]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    return chain.invoke({\"generated_answer\": generated_answer})\n",
    "\n",
    "evaluate_hallucination(chat(question, retriever.invoke(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term \"zero-shot\" refers to the ability of a model, such as a large language model (LLM), to perform tasks without specific training on those tasks. It relies on the model's general understanding and reasoning capabilities, allowing it to generate relevant outputs based on its extensive training data. This concept is significant in the context of LLM-powered autonomous agents, where they can tackle various problems without prior explicit examples.\n"
     ]
    }
   ],
   "source": [
    "#task10\n",
    "\n",
    "def task10_chat(query):\n",
    "    answer = chat(query, retriever.invoke(query))\n",
    "\n",
    "    if evaluate_hallucination(answer)['hallucination'] == 'yes':\n",
    "        answer = chat(query)\n",
    "    \n",
    "    print(answer)\n",
    "\n",
    "\n",
    "task10_chat(\"zero-shot\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
